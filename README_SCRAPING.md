# üì° Reddit Monitor - VERSION SCRAPING

## ‚ö†Ô∏è AVERTISSEMENT IMPORTANT

**Cette version utilise du web scraping** au lieu de l'API officielle Reddit.

### Risques et limitations :

üî¥ **Risques l√©gaux** :
- Le scraping viole les Terms of Service de Reddit
- Risque de ban de compte ou d'IP (temporaire)
- Utilisez √† vos propres risques

üü° **Limitations techniques** :
- Scans **beaucoup plus lents** (10-15 min pour 50 mots-cl√©s)
- Moins de posts par scan (~1000-2000 max vs 5000 avec API)
- Risque de captchas ou blocages

‚ö†Ô∏è **Pr√©cautions obligatoires** :
- **Maximum 1-2 scans par jour**
- D√©lai de 10-15 secondes entre requ√™tes (automatique)
- Usage personnel uniquement (pas commercial)
- Arr√™tez imm√©diatement si Reddit vous bloque

---

## üöÄ Installation

### Pr√©requis

Cette version **NE n√©cessite PAS** de credentials Reddit API !

- Python 3.9+
- Compte Supabase (gratuit)
- Connexion internet stable

### Setup rapide

1. **Extraire l'archive**
```bash
unzip reddit-monitor-scraping.zip
cd reddit-monitor
```

2. **Installer les d√©pendances**
```bash
pip install -r requirements.txt
```

3. **Configurer Supabase**

Cr√©ez un compte sur https://supabase.com et :
- Nouveau projet
- Ex√©cutez `database_schema.sql` dans SQL Editor
- R√©cup√©rez URL et cl√© dans Settings > API

4. **Cr√©er `.streamlit/secrets.toml`**

```toml
[supabase]
url = "https://votre-projet.supabase.co"
key = "VOTRE_CLE_ANON"

# PLUS BESOIN DE CREDENTIALS REDDIT !
```

5. **Lancer l'app**
```bash
streamlit run app.py
```

---

## üìä Diff√©rences avec la version API

| Feature | Version API | Version Scraping |
|---------|-------------|------------------|
| **Setup** | N√©cessite app Reddit | ‚ùå Aucun setup Reddit |
| **Vitesse scan** | 2-5 minutes | ‚ö†Ô∏è 10-20 minutes |
| **Posts par scan** | ~5000 | ‚ö†Ô∏è ~1000-2000 |
| **Fr√©quence** | Plusieurs/jour | ‚ö†Ô∏è 1-2 max/jour |
| **Fiabilit√©** | 99% | ‚ö†Ô∏è 90-95% |
| **L√©galit√©** | ‚úÖ 100% l√©gal | ‚ö†Ô∏è Zone grise |
| **Risque ban** | ‚ùå Aucun | ‚ö†Ô∏è Faible mais existant |

---

## üõ°Ô∏è Pr√©cautions d'usage

### Rate limiting automatique

Le code int√®gre des **d√©lais automatiques** :
- 10-15 secondes entre chaque requ√™te
- User-Agent rotation
- Gestion des erreurs 429 (rate limit)

### Fr√©quence recommand√©e

**Maximum par jour** :
- 1 scan avec 20-30 mots-cl√©s
- OU 2 scans avec 10-15 mots-cl√©s chacun

**√âvitez** :
- Scans multiples rapproch√©s
- Plus de 50 mots-cl√©s actifs
- Scans pendant les heures de pointe Reddit

### Si vous √™tes bloqu√©

**Sympt√¥mes** :
- Erreur 429 (Rate Limit)
- Captchas r√©p√©t√©s
- Timeouts

**Solutions** :
1. **Arr√™tez imm√©diatement** de scanner
2. Attendez 1-24 heures
3. R√©duisez le nombre de mots-cl√©s
4. Espacez davantage vos scans

### Bonnes pratiques

‚úÖ **√Ä FAIRE** :
- Limiter √† 20-30 mots-cl√©s max
- 1 scan par jour
- Utiliser whitelist de subreddits
- Surveiller les logs d'erreurs

‚ùå **√Ä √âVITER** :
- Scans automatiques (cron)
- Usage commercial
- Partage/revente des donn√©es
- Scans pendant maintenance Reddit

---

## üîß Comment √ßa marche

### M√©thode utilis√©e

L'app utilise **l'API JSON publique de Reddit** :

```python
url = "https://www.reddit.com/search.json"
params = {'q': keyword, 't': time_filter}
```

Cette m√©thode est :
- Plus fiable que le parsing HTML
- Moins d√©tectable
- Mais toujours dans une zone grise l√©gale

### Headers et protection

Le code utilise :
- User-Agents r√©alistes rotatifs
- Headers HTTP standards
- D√©lais al√©atoires (10-15s)
- Gestion robuste des erreurs

---

## üìù Configuration recommand√©e

### Pour usage optimal

**Mots-cl√©s** :
- 15-20 mots-cl√©s cibl√©s
- Sp√©cifiques (pas trop g√©n√©riques)

**Subreddits** :
- Whitelist de 5-10 subreddits pertinents
- √âvite le bruit et acc√©l√®re le scan

**Param√®tres** :
- P√©riode : "week" (compromis vitesse/r√©sultats)
- Score minimum : 50+ (filtre le spam)

### Exemple config

```
Mots-cl√©s (15) :
- crypto, bitcoin, ethereum
- AI, machine learning, chatgpt
- python, javascript, react
- SEO, marketing, content
- startup, entrepreneur, saas

Whitelist (8 subreddits) :
- cryptocurrency, bitcoin, ethereum
- artificial, machinelearning
- python, javascript
- SEO, Entrepreneur
```

**Temps de scan** : ~8-10 minutes
**Posts attendus** : ~800-1200

---

## üêõ D√©pannage

### Erreur 429 (Rate Limit)

```
‚ö†Ô∏è Rate limit atteint
```

**Solution** :
- L'app attend automatiquement 60 secondes
- Si r√©p√©t√© : stoppez et attendez 1-24h

### Aucun post trouv√©

```
‚ö†Ô∏è Aucun post trouv√© pour 'keyword'
```

**Causes possibles** :
- Mot-cl√© trop sp√©cifique
- P√©riode trop courte (essayez "month")
- Reddit a chang√© son format JSON

**Solution** :
- √âlargir la recherche
- V√©rifier sur Reddit.com que le mot-cl√© donne des r√©sultats

### Timeout

```
‚ùå Timeout pour 'keyword'
```

**Solution** :
- Connexion internet instable
- Relancez le scan
- R√©duisez le nombre de mots-cl√©s

---

## ‚öñÔ∏è Aspects l√©gaux (Important)

### Ce que dit Reddit

**Reddit Terms of Service (Section 5)** :

> "You may not access or search the Services by any means other than our publicly supported interfaces"

Le scraping viole techniquement ces termes.

### Risques r√©els

**Probabilit√© de cons√©quences** :

| Action | Probabilit√© | Cons√©quence |
|--------|-------------|-------------|
| Ban IP temporaire | 5-10% | Pause 1-24h |
| Ban compte Reddit | 1-2% | Compte bloqu√© |
| Poursuites l√©gales | <0.01% | Tr√®s rare |

### Utilisation responsable

Pour **minimiser les risques** :
- Usage strictement personnel
- Pas de revente de donn√©es
- Respecter rate limits
- Arr√™ter si demand√©

### Alternatives l√©gales

Si vous voulez du 100% l√©gal :
- RSS Feeds Reddit (limit√© √† 25 posts)
- Services tiers payants (SocialData, Brand24)
- API officielle (si Reddit approuve votre demande)

---

## üí° Recommandations finales

### Pour TON usage (4 amis)

**Configuration optimale** :
- Chaque utilisateur : 15-20 mots-cl√©s max
- 1 scan par personne par jour
- Total : 4 scans/jour max sur l'app

**R√©sultat attendu** :
- ~800-1000 posts par scan
- ~3000-4000 posts/jour au total
- Risque tr√®s faible

### Si vous voulez jouer safe

**Option prudente** :
- 10 mots-cl√©s par personne
- 1 scan tous les 2 jours
- Whitelist de 5 subreddits

**R√©sultat** :
- ~400-500 posts par scan
- Pratiquement aucun risque

---

## üÜò Support

### En cas de probl√®me

1. **V√©rifiez les logs** dans Streamlit
2. **Consultez** les issues GitHub
3. **Testez** avec 1-2 mots-cl√©s d'abord

### √âvolution vers l'API

Si Reddit approuve votre demande d'API plus tard :
1. R√©installez PRAW : `pip install praw`
2. Remplacez `reddit_scraper.py` par `reddit_client.py`
3. Ajoutez credentials dans `secrets.toml`

---

## üìö Documentation compl√®te

- **README.md** : Documentation g√©n√©rale
- **QUICKSTART.md** : Setup rapide
- **database_schema.sql** : Structure BDD

---

**Utilisez cette version de fa√ßon responsable ! üôè**

*En cas de doute, pr√©f√©rez les RSS Feeds ou une solution payante l√©gale.*
